###############################################################################
#
# Bell, D. M., and D. R. Schlaepfer. Impacts of the data-generating processes and species distribution model complexity on ecological fidelity and global change predictions.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
#
###############################################################################



# '20160304' with 320,000 runs, 23 cores, and c("GLM", "GAM", "MaxEntP", "RF", "BRT")
#	do.SDMs			2016/03/07 completed in 1262 core-hours
#	do.RegionEvals	2016/03/07 completed in 483 core-hours
#	do.Partition	2016/03/12 completed in 664 core-hours
#	do.Complexity	2016/02/25 completed in 1.5 core-hours
#	do.Evaluation	2016/02/26 completed in 2.2 core-hours


# '20160223' with 320,000 runs, 22 cores, and c("GLM", "GAM", "MaxEnt", "RF", "BRT")
#	do.SDMs			2016/02/24 completed in 237 core-hours
#	do.RegionEvals	2016/02/26 completed in 482 core-hours
#	do.Partition
#	do.Complexity	2016/02/25 completed in 1.5 core-hours
#	do.Evaluation	2016/02/26 completed in 2.2 core-hours



###################################################
#TODOs
#  - (Dave) Check GAMs convergence information to check that poor GAM with interaction performance is not caused by misspecified convergence parameters etc.
#	- scatter plot of TSS/kappa/ROC vs. RMSE + linear fit -> which performance measures represents underlying probability fits most realistically
#	- decide on absence data:
#		- repeating subsampling
#		- prevalence=0.5
#	- decide on how many repeated drawing of presence data (currently at 40 realizations)
#	- decide on how many evaluation splits (currently at 10 calibrations/evaluations) 
#   - decide how to measure uncertainty (currently standard deviations)
#	- maps:
#		- (Dave) raster maps
#		- decide on spatial resolution of projected maps (1/32-degrees vs 800 m)
#		- figures with all four regions as panels of one file?
#Done
#	- Error check new subsampling protocols
#	- Rewrite data sampling and biomod calls to enforce proper subsampling
#	- model formulae should use centered variables for squared and interaction terms
#	- parallelize model building
#	- evaluate model values with 'true' probabilities: RMSE, deviance
#	- figures: response curves with Elith's lines
#	- center variables with mean from basis region (here, region 2) for variables from all regions
#	- We are not concerned about Warnings: glm.fit: fitted probabilities numerically 0 or 1 occurred
#	- Repeated splitting of data into calibration and validation outside of biomod2
#	- Repeated drawing of presence data from underlying probabilities (realizations)
#		--> data from files is read only once and presence realizations made: all functions draw from this R object instead of repeated reading from files
#		--> SAMP object moved from 'do.SDMs' section to inside function 'make.biomod2sSDM' otherwise object size would become quite large
#	- Added option 'do.ExampleForDropbox': if set to TRUE, then output saved to separate folders on dropbox to serve as examples during code development
#	- Added figures showing scatter between predicted and true probabilities
#	- Code is more verbose and checks for successful completion of SDMs, evaluations, and figures
#	- Temporary evaluation arrays are organized by realization and data-split replications
#	- Fixed important bug in evalX.SDMs:
#		(i) biomod2-evaluations were calculated based on incorrect presence-data realization
#		(ii) rmse and mae evaluations were based on presence-data instead of underlying probabilities of occurrence
#	- Parallelization cannot handle our bres object with 40 realizations x 50 data-split repeats (ca. 13 GB in memory): export to slaves is done via un/serialize with long vectors if needed, but long vectors are not (yet) supported by Rmpi
#		-> DOESN'T WORK: using snow with foreach
#		-> works: added direct Rmpi master-slave communication with function work() which allows only passing a subset of bres that is actually required for one evaluation/figure set (subsets are ca. 0.7-1.8 GB in memory)
#   - (Dave) Rewrite model fitting code to use glm and gam functions directly
#	- (Dave) reduce memory needs/storage (roughly 90% reduction in model and projection memory)
#		--> (done) store predictions as integers 
#		--> (done) minimize model storage (after predictions are made, we do not really need most of the model output)
#	- (Dave) Do the figures "Fig_TrueVsPredictedProbs_*.pdf" generated by plot_scatterPredvsTrueProbs() make sense?
#		-> they are rather skewed to (low obs/high pred) values
#		-> This was a problem with biomod that was corrected by modeling SDMs directly with glm and gam functions
#	- (Daniel) Update response curve functions to account for new data structure; predictions happen now only in the make.sdm() function
#	- (Daniel) Scale maps uniformly for easy comparison
#	- (Daniel) Draw 68% and 90% of model response curves instead of min-median-max
#	- (Daniel) Make plot with differences of performance measures to base region, plus base region values
#	- (Dave) Partition variation from realization vs data-split repeats -- Use Sum of Squares from aov function
###################################################
